{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Machine Learning Project Template  A template for machine learning or deep learning projects."},{"location":"#features","title":"\ud83e\udde0 Features","text":"<ul> <li>[x] Easy to implement your own model and dataloader through hydra instantiation of datamodules and models</li> <li>[x] Configurable hyperparameters with Hydra</li> <li>[x] Logging with the solution that fits your needs</li> <li>[x] Works on CPU, multi-GPU, and multi-TPUs</li> <li>[x] Use bleeding edge UV to manage packages</li> <li>[x] pre-commits hooks to validate code style and quality</li> <li>[x] Hydra instantiation of models and dataloaders</li> <li>[x] torch.compile of models</li> <li>[x] Tensors typing validation with TorchTyping</li> <li>[x] Dockerized project (Dockerfile, run tests and training through docker, optionally docker-compose)</li> <li>[x] Examples of efficient multi-processing using python's pool map</li> <li>[x] Examples using polars for faster and more efficient dataframe processing</li> <li>[x] Example of mock tests using pytest</li> <li>[x] Util scripts to download dataset from kaggle</li> <li>[x] Cloud data retrieval using cloudpathlib (launch your training on AWS, GCP, Azure)</li> <li>[x] Architecture and example of creating the model serving API through LitServe</li> <li>[x] Wiki creation and setup of documentation website with best integrations through Mkdocs</li> </ul>"},{"location":"#steps-for-installation","title":"\u2699\ufe0f Steps for Installation","text":"<ul> <li>[ ] Use this repository as a template</li> <li>[ ] Clone your repository</li> <li>[ ] Run <code>make install</code> to install the dependencies</li> <li>[ ] Add your model which inherits from <code>LightningModule</code> in <code>src/models</code></li> <li>[ ] Add your dataset which inherits from <code>Datamodule</code> in <code>src/data</code></li> <li>[ ] Add associated yaml configuration files in <code>configs/</code> folder following existing examples</li> <li>[ ] Read the commands in the Makefile to understand the available commands you can use</li> </ul>"},{"location":"#tips-and-tricks","title":"\ud83e\udd20Tips and Tricks","text":""},{"location":"#how-does-the-project-work","title":"\ud83d\udc0d How does the project work?","text":"<p>The <code>train.py</code> or <code>eval.py</code> script is the entry point of the project. It uses Hydra to instantiate the model (LightningModule), dataloader (DataModule), and trainer using the configuration reconstructed using Hydra. The model is then trained or evaluated using Pytorch Lightning. The  <code>serve.py</code> is used to serve the model through a REST API using LitServe and based on the <code>configs/serve.yaml</code> configuration file.</p>"},{"location":"#implementing-your-logic","title":"\ud83d\udc40 Implementing your logic","text":"<p>You don't need to worry about implementing the training loops, the support for different hardwares, reading of configurations, etc. You need to care about 4 files for each training : your LightningModule (+ its hydra config), your DataModule (+ its hydra config).</p> <p>In the LightningModule, you need to implement the following methods:</p> <ul> <li><code>forward method</code></li> <li><code>training_step</code></li> <li><code>validation_step</code></li> <li><code>test_step</code></li> </ul> <p>Get inspired by the provided examples in the <code>src/models</code> folder. For the DataModule, you need to implement the following methods:</p> <ul> <li><code>prepare_data</code></li> <li><code>setup</code></li> <li><code>train_dataloader</code></li> <li><code>val_dataloader</code></li> <li><code>test_dataloader</code></li> </ul> <p>Get inspired by the provided examples in the <code>src/data</code> folder.</p> <p>Get to know more about Pytorch Lightning's LightningModule and DataModule in the Pytorch Lightning documentation. Finally in the associated configs/ folder, you need to implement the yaml configuration files for the model and dataloader.</p>"},{"location":"#the-power-of-hydra","title":"\ud83d\udd0d The power of Hydra","text":"<p>As Hydra is used for configuration, you can easily change the hyperparameters of your model, the dataloader, the trainer, etc. by changing the yaml configuration files in the <code>configs/</code> folder. You can also use the <code>--multirun</code> option to run multiple experiments with different configurations.</p> <p>But also, as it used to instantiate the model and dataloader, you can easily change the model, dataloader, or any other component by changing the yaml configuration files or DIRECTLY IN COMMAND LINE. This is especially useful when you want to use different models or dataloaders.</p> <p>For example, you can run the following command to train a model with a different architecture, changing the dataset used, and the trainer used:</p> <pre><code>uv run src/train.py model=LeNet datamodule=MNISTDataModule trainer=gpu\n</code></pre> <p>Read more about Hydra in the official documentation.</p>"},{"location":"#best-practices","title":"\ud83d\udca1 Best practices","text":"<ul> <li>Typing your functions and classes with <code>TorchTyping</code> for better type checking (in addition to python's typing module)</li> <li>Docstring your functions and classes, it is even more important as it is used to generate the documentation with Mkdocs</li> <li>Use the <code>make</code> commands to run your code, it is easier and faster than writing the full command (and check the Makefile for all available commands \ud83d\ude09)</li> <li>Use the pre-commit hooks to ensure your code is formatted correctly and is of good quality</li> <li>UV is powerful (multi-thread, package graph solving, rust backend, etc.) use it as much as you can.</li> <li>If you have a lot of data, use Polars for faster and more efficient dataframe processing.</li> <li>If you have CPU intensive tasks, use multi-processing with python's pool map, you can find an example in the <code>src/utils/utils.py</code> file.</li> </ul>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>You have the possibility to generate a documentation website using Mkdocs. It will automatically generate the documentation based on both the markdown files in the <code>docs/</code> folder and the docstrings in your code. To generate and serve the documentation locally:</p> <pre><code>make serve-docs # Documentation will be available at http://localhost:8000\n</code></pre> <p>And to deploy it to Github pages (youn need to enable Pages in your repository configuration and set it to use the gh-pages branch):</p> <pre><code>make pages-deploy # It will create a gh-pages branch and push the documentation to it\n</code></pre>"},{"location":"#github-templates","title":"\ud83c\udf93 Github Templates","text":"<p>This repository uses Github templates to help you with issues, pull requests, and discussions. It is a great way to standardize the way your team interacts with the repository. You can customize the templates to fit your needs. They can be find in .github folder.</p>"},{"location":"#use-this-template-as-your-juniors-on-boarding-process","title":"\ud83d\ude80 Use this template as your junior's on-boarding process","text":"<p>This template is perfect for your junior's on-boarding process. It has all the best practices and tools to make them productive from day one. It is also a great way to ensure that your team follows the same best practices and tools. For example you can select as a start a training notebook for any dataset on Kaggle, and ask your junior to industrialize the notebook into a full-fledged project. It will help them to understand the best practices and tools used in the industry. After selecting the dataset and notebook, potential steps for the junior can be:</p> <ul> <li>Implement the DataModule and the LightningModule</li> <li>Implement the associated yaml configuration files and use Hydra to instantiate important classes</li> <li>Implement the training script</li> <li>Implement the evaluation script</li> <li>Implement unit tests</li> <li>Create a CI/CD pipeline with Github Actions</li> <li>Dockerize the project</li> <li>Create a Makefile with useful commands</li> <li>Implement the documentation with Mkdocs (All of this while following the best practices and tools provided in the template and PEP8)</li> </ul> <p>If any struggle is encountered, the junior can refer to the provided examples in the project.</p>"},{"location":"#tree-explained","title":"\ud83c\udf33 Tree Explained","text":"<pre><code>.\n\u251c\u2500\u2500 commit-template.txt # use this file to set your commit message template, with make configure-commit template\n\u251c\u2500\u2500 configs # configuration files for hydra\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 callbacks # configuration files for callbacks\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data # configuration files for datamodules\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 debug # configuration files for pytorch lightning debuggers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eval.yaml # configuration file for evaluation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 experiment # configuration files for experiments\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 extras # configuration files for extra components\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hparams_search # configuration files for hyperparameters search\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 local # configuration files for local training\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 logger # configuration files for loggers (neptune, wandb, etc.)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model # configuration files for models (LightningModule)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 paths # configuration files for paths\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 trainer # configuration files for trainers (cpu, gpu, tpu)\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 train.yaml # configuration file for training\n\u251c\u2500\u2500 data # data folder (to store potentially downloaded datasets)\n\u251c\u2500\u2500 Makefile # makefile contains useful commands for the project\n\u251c\u2500\u2500 notebooks # notebooks folder\n\u251c\u2500\u2500 pyproject.toml # pyproject.toml file for uv package manager\n\u251c\u2500\u2500 README.md # this file\n\u251c\u2500\u2500 ruff.toml # ruff.toml file for pre-commit\n\u251c\u2500\u2500 scripts # scripts folder\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 example_train.sh\n\u251c\u2500\u2500 src # source code folder\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data # datamodules folder\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 components\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 mnist_datamodule.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eval.py # evaluation entry script\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models # models folder (LightningModule)\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 components # components folder, contains model parts or \"nets\"\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 train.py # training entry script\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 utils # utils folder\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 instantiators.py # instantiators for models and dataloaders\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 logging_utils.py # logger utils\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 pylogger.py # multi-process and multi-gpu safe logging\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 rich_utils.py # rich utils\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 utils.py # general utils like multi-processing, etc.\n\u2514\u2500\u2500 tests # tests folder\n    \u2514\u2500\u2500 conftest.py # fixtures for tests\n    \u2514\u2500\u2500 mock_test.py # example of mocking tests\n</code></pre>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>For more information on how to contribute to this project, please refer to the CONTRIBUTING.md file.</p>"},{"location":"#acknowledgements","title":"\ud83c\udf1f Acknowledgements","text":"<p>This template was heavily inspired by great existing ones, like:</p> <ul> <li>Lightning Hydra Template</li> <li>Pytorch Tempest</li> <li>Yet Another Lightning Hydra Template</li> <li>Pytorch Style Guide </li> </ul> <p>But with a few opininated changes and improvements, go check them out!</p>"},{"location":"api/eval/","title":"Eval","text":"<p>Main evaluation script.</p>"},{"location":"api/eval/#src.eval.evaluate","title":"<code>evaluate(cfg)</code>","text":"<p>Evaluates given checkpoint on a datamodule testset.</p> <p>This method is wrapped in optional @task_wrapper decorator, that controls the behavior during failure. Useful for multiruns, saving info about the crash, etc.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>DictConfig configuration composed by Hydra.</p> required <p>Returns:</p> Type Description <code>tuple[dict[str, Any], dict[str, Any]]</code> <p>tuple[dict, dict] with metrics and dict with all instantiated objects.</p> Source code in <code>src/eval.py</code> <pre><code>@task_wrapper\ndef evaluate(cfg: DictConfig) -&gt; tuple[dict[str, Any], dict[str, Any]]:\n    \"\"\"Evaluates given checkpoint on a datamodule testset.\n\n    This method is wrapped in optional @task_wrapper decorator, that controls the behavior during\n    failure. Useful for multiruns, saving info about the crash, etc.\n\n    Args:\n        cfg: DictConfig configuration composed by Hydra.\n\n    Returns:\n        tuple[dict, dict] with metrics and dict with all instantiated objects.\n    \"\"\"\n    assert cfg.ckpt_path\n\n    log.info(f\"Instantiating datamodule &lt;{cfg.data._target_}&gt;\")\n    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.data)\n\n    log.info(f\"Instantiating model &lt;{cfg.model._target_}&gt;\")\n    model: LightningModule = hydra.utils.instantiate(cfg.model)\n\n    if cfg.get(\"model_compile\", False):\n        log.info(\"Compiling model...\")\n        torch.compile(model)\n\n    log.info(\"Instantiating loggers...\")\n    logger: list[Logger] = instantiate_loggers(cfg.get(\"logger\"))\n\n    log.info(f\"Instantiating trainer &lt;{cfg.trainer._target_}&gt;\")\n    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, logger=logger)\n\n    object_dict = {\n        \"cfg\": cfg,\n        \"datamodule\": datamodule,\n        \"model\": model,\n        \"logger\": logger,\n        \"trainer\": trainer,\n    }\n\n    if logger:\n        log.info(\"Logging hyperparameters!\")\n        log_hyperparameters(object_dict)\n\n    log.info(\"Starting testing!\")\n    trainer.test(model=model, datamodule=datamodule, ckpt_path=cfg.ckpt_path)\n\n    # for predictions use trainer.predict(...)\n    # predictions = trainer.predict(model=model, dataloaders=dataloaders, ckpt_path=cfg.ckpt_path)\n\n    metric_dict = trainer.callback_metrics\n\n    return metric_dict, object_dict\n</code></pre>"},{"location":"api/eval/#src.eval.main","title":"<code>main(cfg)</code>","text":"<p>Main entry point for evaluation.</p> <p>:param cfg: DictConfig configuration composed by Hydra.</p> Source code in <code>src/eval.py</code> <pre><code>@hydra.main(version_base=\"1.3\", config_path=\"../configs\", config_name=\"eval.yaml\")\ndef main(cfg: DictConfig) -&gt; None:\n    \"\"\"Main entry point for evaluation.\n\n    :param cfg: DictConfig configuration composed by Hydra.\n    \"\"\"\n    # apply extra utilities\n    # (e.g. ask for tags if none are provided in cfg, print cfg tree, etc.)\n    extras(cfg)\n\n    evaluate(cfg)\n</code></pre>"},{"location":"api/serve/","title":"Serve","text":"<p>Main serve script.</p>"},{"location":"api/serve/#src.serve.main","title":"<code>main(cfg)</code>","text":"<p>Main entry point for serving.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>DictConfig configuration composed by Hydra.</p> required <p>Returns:</p> Type Description <code>None</code> <p>Optional[float] with optimized metric value.</p> Source code in <code>src/serve.py</code> <pre><code>@hydra.main(version_base=\"1.3\", config_path=\"../configs\", config_name=\"serve.yaml\")\ndef main(cfg: DictConfig) -&gt; None:\n    \"\"\"Main entry point for serving.\n\n    Args:\n        cfg: DictConfig configuration composed by Hydra.\n\n    Returns:\n        Optional[float] with optimized metric value.\n    \"\"\"\n    serve(cfg)\n</code></pre>"},{"location":"api/serve/#src.serve.serve","title":"<code>serve(cfg)</code>","text":"<p>Serve the specified model in the configuration as a FastAPI api.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>A DictConfig configuration composed by Hydra.</p> required <p>Returns:</p> Type Description <code>None</code> <p>A tuple with metrics and dict with all instantiated objects.</p> Source code in <code>src/serve.py</code> <pre><code>@task_wrapper\ndef serve(cfg: DictConfig) -&gt; None:\n    \"\"\"Serve the specified model in the configuration as a FastAPI api.\n\n    Args:\n        cfg: A DictConfig configuration composed by Hydra.\n\n    Returns:\n        A tuple with metrics and dict with all instantiated objects.\n    \"\"\"\n    # set seed for random number generators in pytorch, numpy and python.random\n    if cfg.get(\"seed\"):\n        lightning.seed_everything(cfg.seed, workers=True)\n    log.info(f\"Getting model class &lt;{cfg.model._target_}&gt;\")\n    model_class = hydra.utils.get_class(cfg.model._target_)\n    lit_server_api = hydra.utils.instantiate(cfg.serve.api, model_class=model_class)\n    # Create the LitServe server with the MNISTServeAPI\n    server = ls.LitServer(lit_server_api, accelerator=cfg.serve.accelerator, max_batch_size=cfg.serve.max_batch_size)\n    log.info(\"Initialized LitServe server\")\n    # Run the server on port 8000\n    log.info(f\"Starting LitServe server on port {cfg.serve.port}\")\n    server.run(port=cfg.serve.port)\n</code></pre>"},{"location":"api/train/","title":"Train","text":"<p>Main training script.</p>"},{"location":"api/train/#src.train.main","title":"<code>main(cfg)</code>","text":"<p>Main entry point for training.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>DictConfig configuration composed by Hydra.</p> required <p>Returns:</p> Type Description <code>float | None</code> <p>Optional[float] with optimized metric value.</p> Source code in <code>src/train.py</code> <pre><code>@hydra.main(version_base=\"1.3\", config_path=\"../configs\", config_name=\"train.yaml\")\ndef main(cfg: DictConfig) -&gt; float | None:\n    \"\"\"Main entry point for training.\n\n    Args:\n        cfg: DictConfig configuration composed by Hydra.\n\n    Returns:\n        Optional[float] with optimized metric value.\n    \"\"\"\n    # apply extra utilities\n    # (e.g. ask for tags if none are provided in cfg, print cfg tree, etc.)\n    extras(cfg)\n\n    # train the model\n    metric_dict, _ = train(cfg)\n\n    # safely retrieve metric value for hydra-based hyperparameter optimization\n    metric_value = get_metric_value(metric_dict=metric_dict, metric_name=cfg.get(\"optimized_metric\"))\n\n    # return optimized metric\n    return metric_value\n</code></pre>"},{"location":"api/train/#src.train.train","title":"<code>train(cfg)</code>","text":"<p>Trains the model. Can additionally evaluate on a testset, using best weights obtained during training.</p> <p>This method is wrapped in optional @task_wrapper decorator, that controls the behavior during failure. Useful for multiruns, saving info about the crash, etc.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>A DictConfig configuration composed by Hydra.</p> required <p>Returns:</p> Type Description <code>tuple[dict[str, Any], dict[str, Any]]</code> <p>A tuple with metrics and dict with all instantiated objects.</p> Source code in <code>src/train.py</code> <pre><code>@task_wrapper\ndef train(cfg: DictConfig) -&gt; tuple[dict[str, Any], dict[str, Any]]:\n    \"\"\"Trains the model. Can additionally evaluate on a testset, using best weights obtained during training.\n\n    This method is wrapped in optional @task_wrapper decorator, that controls the behavior during\n    failure. Useful for multiruns, saving info about the crash, etc.\n\n    Args:\n        cfg: A DictConfig configuration composed by Hydra.\n\n    Returns:\n        A tuple with metrics and dict with all instantiated objects.\n    \"\"\"\n    # set seed for random number generators in pytorch, numpy and python.random\n    if cfg.get(\"seed\"):\n        lightning.seed_everything(cfg.seed, workers=True)\n\n    log.info(f\"Instantiating datamodule &lt;{cfg.data._target_}&gt;\")\n    datamodule: LightningDataModule = hydra.utils.instantiate(cfg.data)\n\n    log.info(f\"Instantiating model &lt;{cfg.model._target_}&gt;\")\n    model: LightningModule = hydra.utils.instantiate(cfg.model)\n\n    if cfg.get(\"model_compile\", False):\n        log.info(\"Compiling model...\")\n        torch.compile(model)\n\n    log.info(\"Instantiating callbacks...\")\n    callbacks: list[Callback] = instantiate_callbacks(cfg.get(\"callbacks\"))\n\n    log.info(\"Instantiating loggers...\")\n    logger: list[Logger] = instantiate_loggers(cfg.get(\"logger\"))\n\n    log.info(f\"Instantiating trainer &lt;{cfg.trainer._target_}&gt;\")\n    trainer: Trainer = hydra.utils.instantiate(cfg.trainer, callbacks=callbacks, logger=logger)\n\n    object_dict = {\n        \"cfg\": cfg,\n        \"datamodule\": datamodule,\n        \"model\": model,\n        \"callbacks\": callbacks,\n        \"logger\": logger,\n        \"trainer\": trainer,\n    }\n\n    if logger:\n        log.info(\"Logging hyperparameters!\")\n        log_hyperparameters(object_dict)\n\n    if cfg.get(\"train\"):\n        log.info(\"Starting training!\")\n        trainer.fit(model=model, datamodule=datamodule, ckpt_path=cfg.get(\"ckpt_path\"))\n\n    train_metrics = trainer.callback_metrics\n\n    if cfg.get(\"test\"):\n        log.info(\"Starting testing!\")\n        assert trainer.checkpoint_callback is not None\n        ckpt_path = trainer.checkpoint_callback.best_model_path  # type: ignore\n        if ckpt_path == \"\":\n            log.warning(\"Best ckpt not found! Using current weights for testing...\")\n            ckpt_path = None\n        trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)\n        log.info(f\"Best ckpt path: {ckpt_path}\")\n\n    test_metrics = trainer.callback_metrics\n\n    # merge train and test metrics\n    metric_dict = {**train_metrics, **test_metrics}\n\n    return metric_dict, object_dict\n</code></pre>"},{"location":"api/data/mnist_datamodule/","title":"Mnist datamodule","text":"<p>MNIST DataModule.</p>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule","title":"<code>MNISTDataModule</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p><code>LightningDataModule</code> for the MNIST dataset.</p> <p>The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. The original black and white images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.</p> <p>A <code>LightningDataModule</code> implements 7 key methods:</p> <pre><code>    def prepare_data(self):\n    # Things to do on 1 GPU/TPU (not on every GPU/TPU in DDP).\n    # Download data, pre-process, split, save to disk, etc...\n\n    def setup(self, stage):\n    # Things to do on every process in DDP.\n    # Load data, set variables, etc...\n\n    def train_dataloader(self):\n    # return train dataloader\n\n    def val_dataloader(self):\n    # return validation dataloader\n\n    def test_dataloader(self):\n    # return test dataloader\n\n    def predict_dataloader(self):\n    # return predict dataloader\n\n    def teardown(self, stage):\n    # Called on every process in DDP.\n    # Clean up after fit or test.\n</code></pre> <p>This allows you to share a full dataset without explaining how to download, split, transform and process the data.</p> Read the docs <p>https://lightning.ai/docs/pytorch/latest/data/datamodule.html</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>class MNISTDataModule(LightningDataModule):\n    \"\"\"`LightningDataModule` for the MNIST dataset.\n\n    The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples.\n    It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a\n    fixed-size image. The original black and white images from NIST were size normalized to fit in a 20x20 pixel box\n    while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing\n    technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of\n    mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.\n\n    A `LightningDataModule` implements 7 key methods:\n\n    ```python\n        def prepare_data(self):\n        # Things to do on 1 GPU/TPU (not on every GPU/TPU in DDP).\n        # Download data, pre-process, split, save to disk, etc...\n\n        def setup(self, stage):\n        # Things to do on every process in DDP.\n        # Load data, set variables, etc...\n\n        def train_dataloader(self):\n        # return train dataloader\n\n        def val_dataloader(self):\n        # return validation dataloader\n\n        def test_dataloader(self):\n        # return test dataloader\n\n        def predict_dataloader(self):\n        # return predict dataloader\n\n        def teardown(self, stage):\n        # Called on every process in DDP.\n        # Clean up after fit or test.\n    ```\n\n    This allows you to share a full dataset without explaining how to download,\n    split, transform and process the data.\n\n    Read the docs:\n        https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n    \"\"\"\n\n    def __init__(\n        self,\n        data_dir: str = \"data/\",\n        train_val_test_split: tuple[int, int, int] = (55_000, 5_000, 10_000),\n        batch_size: int = 64,\n        num_workers: int = 0,\n        pin_memory: bool = False,\n    ) -&gt; None:\n        \"\"\"Initialize a `MNISTDataModule`.\n\n        Args:\n            data_dir: The data directory. Defaults to `\"data/\"`.\n            train_val_test_split: The train, validation and test split. Defaults to `(55_000, 5_000, 10_000)`.\n            batch_size: The batch size. Defaults to `64`.\n            num_workers: The number of workers. Defaults to `0`.\n            pin_memory: Whether to pin memory. Defaults to `False`.\n        \"\"\"\n        super().__init__()\n\n        # this line allows to access init params with 'self.hparams' attribute\n        # also ensures init params will be stored in ckpt\n        self.save_hyperparameters(logger=False)\n\n        # data transformations\n        self.transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n\n        self.data_train: Dataset | None = None\n        self.data_val: Dataset | None = None\n        self.data_test: Dataset | None = None\n\n        self.batch_size_per_device = batch_size\n\n    @property\n    def num_classes(self) -&gt; int:\n        \"\"\"Get the number of classes.\n\n        :return: The number of MNIST classes (10).\n        \"\"\"\n        return 10\n\n    def prepare_data(self) -&gt; None:\n        \"\"\"Download data if needed.\n\n        Lightning ensures that `self.prepare_data()` is called only\n        within a single process on CPU, so you can safely add your downloading logic within. In\n        case of multi-node training, the execution of this hook depends upon\n        `self.prepare_data_per_node()`.\n\n        Do not use it to assign state (self.x = y).\n        \"\"\"\n        MNIST(self.hparams[\"data_dir\"], train=True, download=True)\n        MNIST(self.hparams[\"data_dir\"], train=False, download=True)\n\n    def setup(self, stage: str | None = None) -&gt; None:\n        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n\n        This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and\n        `trainer.predict()`, so be careful not to execute things like random split twice! Also, it is called after\n        `self.prepare_data()` and there is a barrier in between which ensures that all the processes proceed to\n        `self.setup()` once the data is prepared and available for use.\n\n        Args:\n            stage: The stage to setup. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`. Defaults to ``None``.\n        \"\"\"\n        # Divide batch size by the number of devices.\n        if self.trainer is not None:\n            if self.hparams[\"batch_size\"] % self.trainer.world_size != 0:\n                raise RuntimeError(  # noqa\n                    f\"Batch size ({self.hparams['batch_size']}) \"\n                    \"is not divisible by the number of devices ({self.trainer.world_size}).\"\n                )\n            self.batch_size_per_device = self.hparams[\"batch_size\"] // self.trainer.world_size\n\n        # load and split datasets only if not loaded already\n        if not self.data_train and not self.data_val and not self.data_test:\n            assert self.hparams[\"data_dir\"] is not None\n            trainset = MNIST(self.hparams[\"data_dir\"], train=True, transform=self.transforms)\n            testset = MNIST(self.hparams[\"data_dir\"], train=False, transform=self.transforms)\n            dataset: ConcatDataset = ConcatDataset(datasets=[trainset, testset])\n            self.data_train, self.data_val, self.data_test = random_split(\n                dataset=dataset,\n                lengths=self.hparams[\"train_val_test_split\"],\n                generator=torch.Generator().manual_seed(42),\n            )\n\n    def train_dataloader(self) -&gt; DataLoader[Any]:\n        \"\"\"Create and return the train dataloader.\n\n        Returns:\n            The train dataloader.\n        \"\"\"\n        assert self.data_train is not None\n        return DataLoader(\n            dataset=self.data_train,\n            batch_size=self.batch_size_per_device,\n            num_workers=self.hparams[\"num_workers\"],\n            pin_memory=self.hparams[\"pin_memory\"],\n            shuffle=True,\n        )\n\n    def val_dataloader(self) -&gt; DataLoader[Any]:\n        \"\"\"Create and return the validation dataloader.\n\n        Returns:\n            The validation dataloader.\n        \"\"\"\n        assert self.data_val is not None\n        return DataLoader(\n            dataset=self.data_val,\n            batch_size=self.batch_size_per_device,\n            num_workers=self.hparams[\"num_workers\"],\n            pin_memory=self.hparams[\"pin_memory\"],\n            shuffle=False,\n        )\n\n    def test_dataloader(self) -&gt; DataLoader[Any]:\n        \"\"\"Create and return the test dataloader.\n\n        Returns:\n            The test dataloader.\n        \"\"\"\n        assert self.data_test is not None\n        return DataLoader(\n            dataset=self.data_test,\n            batch_size=self.batch_size_per_device,\n            num_workers=self.hparams[\"num_workers\"],\n            pin_memory=self.hparams[\"pin_memory\"],\n            shuffle=False,\n        )\n\n    def teardown(self, stage: str | None = None) -&gt; None:\n        \"\"\"Lightning hook for cleaning up after trainer main functions.\n\n        `trainer.fit()`, `trainer.validate()`,`trainer.test()`, and `trainer.predict()`.\n\n        Args:\n            stage: The stage being torn down. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n            Defaults to ``None``.\n        \"\"\"\n        pass\n\n    def state_dict(self) -&gt; dict[Any, Any]:\n        \"\"\"Called when saving a checkpoint. Implement to generate and save the datamodule state.\n\n        Returns:\n            A dictionary containing the datamodule state that you want to save.\n        \"\"\"\n        return {}\n\n    def load_state_dict(self, state_dict: dict[str, Any]) -&gt; None:\n        \"\"\"Called when loading a checkpoint. Implement to reload datamodule state given datamodule `state_dict()`.\n\n        Args:\n            state_dict: The datamodule state returned by `self.state_dict()`.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.num_classes","title":"<code>num_classes: int</code>  <code>property</code>","text":"<p>Get the number of classes.</p> <p>:return: The number of MNIST classes (10).</p>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.__init__","title":"<code>__init__(data_dir='data/', train_val_test_split=(55000, 5000, 10000), batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Initialize a <code>MNISTDataModule</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>The data directory. Defaults to <code>\"data/\"</code>.</p> <code>'data/'</code> <code>train_val_test_split</code> <code>tuple[int, int, int]</code> <p>The train, validation and test split. Defaults to <code>(55_000, 5_000, 10_000)</code>.</p> <code>(55000, 5000, 10000)</code> <code>batch_size</code> <code>int</code> <p>The batch size. Defaults to <code>64</code>.</p> <code>64</code> <code>num_workers</code> <code>int</code> <p>The number of workers. Defaults to <code>0</code>.</p> <code>0</code> <code>pin_memory</code> <code>bool</code> <p>Whether to pin memory. Defaults to <code>False</code>.</p> <code>False</code> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def __init__(\n    self,\n    data_dir: str = \"data/\",\n    train_val_test_split: tuple[int, int, int] = (55_000, 5_000, 10_000),\n    batch_size: int = 64,\n    num_workers: int = 0,\n    pin_memory: bool = False,\n) -&gt; None:\n    \"\"\"Initialize a `MNISTDataModule`.\n\n    Args:\n        data_dir: The data directory. Defaults to `\"data/\"`.\n        train_val_test_split: The train, validation and test split. Defaults to `(55_000, 5_000, 10_000)`.\n        batch_size: The batch size. Defaults to `64`.\n        num_workers: The number of workers. Defaults to `0`.\n        pin_memory: Whether to pin memory. Defaults to `False`.\n    \"\"\"\n    super().__init__()\n\n    # this line allows to access init params with 'self.hparams' attribute\n    # also ensures init params will be stored in ckpt\n    self.save_hyperparameters(logger=False)\n\n    # data transformations\n    self.transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n\n    self.data_train: Dataset | None = None\n    self.data_val: Dataset | None = None\n    self.data_test: Dataset | None = None\n\n    self.batch_size_per_device = batch_size\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.load_state_dict","title":"<code>load_state_dict(state_dict)</code>","text":"<p>Called when loading a checkpoint. Implement to reload datamodule state given datamodule <code>state_dict()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <code>dict[str, Any]</code> <p>The datamodule state returned by <code>self.state_dict()</code>.</p> required Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def load_state_dict(self, state_dict: dict[str, Any]) -&gt; None:\n    \"\"\"Called when loading a checkpoint. Implement to reload datamodule state given datamodule `state_dict()`.\n\n    Args:\n        state_dict: The datamodule state returned by `self.state_dict()`.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Download data if needed.</p> <p>Lightning ensures that <code>self.prepare_data()</code> is called only within a single process on CPU, so you can safely add your downloading logic within. In case of multi-node training, the execution of this hook depends upon <code>self.prepare_data_per_node()</code>.</p> <p>Do not use it to assign state (self.x = y).</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def prepare_data(self) -&gt; None:\n    \"\"\"Download data if needed.\n\n    Lightning ensures that `self.prepare_data()` is called only\n    within a single process on CPU, so you can safely add your downloading logic within. In\n    case of multi-node training, the execution of this hook depends upon\n    `self.prepare_data_per_node()`.\n\n    Do not use it to assign state (self.x = y).\n    \"\"\"\n    MNIST(self.hparams[\"data_dir\"], train=True, download=True)\n    MNIST(self.hparams[\"data_dir\"], train=False, download=True)\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.setup","title":"<code>setup(stage=None)</code>","text":"<p>Load data. Set variables: <code>self.data_train</code>, <code>self.data_val</code>, <code>self.data_test</code>.</p> <p>This method is called by Lightning before <code>trainer.fit()</code>, <code>trainer.validate()</code>, <code>trainer.test()</code>, and <code>trainer.predict()</code>, so be careful not to execute things like random split twice! Also, it is called after <code>self.prepare_data()</code> and there is a barrier in between which ensures that all the processes proceed to <code>self.setup()</code> once the data is prepared and available for use.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str | None</code> <p>The stage to setup. Either <code>\"fit\"</code>, <code>\"validate\"</code>, <code>\"test\"</code>, or <code>\"predict\"</code>. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def setup(self, stage: str | None = None) -&gt; None:\n    \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n\n    This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and\n    `trainer.predict()`, so be careful not to execute things like random split twice! Also, it is called after\n    `self.prepare_data()` and there is a barrier in between which ensures that all the processes proceed to\n    `self.setup()` once the data is prepared and available for use.\n\n    Args:\n        stage: The stage to setup. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`. Defaults to ``None``.\n    \"\"\"\n    # Divide batch size by the number of devices.\n    if self.trainer is not None:\n        if self.hparams[\"batch_size\"] % self.trainer.world_size != 0:\n            raise RuntimeError(  # noqa\n                f\"Batch size ({self.hparams['batch_size']}) \"\n                \"is not divisible by the number of devices ({self.trainer.world_size}).\"\n            )\n        self.batch_size_per_device = self.hparams[\"batch_size\"] // self.trainer.world_size\n\n    # load and split datasets only if not loaded already\n    if not self.data_train and not self.data_val and not self.data_test:\n        assert self.hparams[\"data_dir\"] is not None\n        trainset = MNIST(self.hparams[\"data_dir\"], train=True, transform=self.transforms)\n        testset = MNIST(self.hparams[\"data_dir\"], train=False, transform=self.transforms)\n        dataset: ConcatDataset = ConcatDataset(datasets=[trainset, testset])\n        self.data_train, self.data_val, self.data_test = random_split(\n            dataset=dataset,\n            lengths=self.hparams[\"train_val_test_split\"],\n            generator=torch.Generator().manual_seed(42),\n        )\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.state_dict","title":"<code>state_dict()</code>","text":"<p>Called when saving a checkpoint. Implement to generate and save the datamodule state.</p> <p>Returns:</p> Type Description <code>dict[Any, Any]</code> <p>A dictionary containing the datamodule state that you want to save.</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def state_dict(self) -&gt; dict[Any, Any]:\n    \"\"\"Called when saving a checkpoint. Implement to generate and save the datamodule state.\n\n    Returns:\n        A dictionary containing the datamodule state that you want to save.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.teardown","title":"<code>teardown(stage=None)</code>","text":"<p>Lightning hook for cleaning up after trainer main functions.</p> <p><code>trainer.fit()</code>, <code>trainer.validate()</code>,<code>trainer.test()</code>, and <code>trainer.predict()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str | None</code> <p>The stage being torn down. Either <code>\"fit\"</code>, <code>\"validate\"</code>, <code>\"test\"</code>, or <code>\"predict\"</code>.</p> <code>None</code> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def teardown(self, stage: str | None = None) -&gt; None:\n    \"\"\"Lightning hook for cleaning up after trainer main functions.\n\n    `trainer.fit()`, `trainer.validate()`,`trainer.test()`, and `trainer.predict()`.\n\n    Args:\n        stage: The stage being torn down. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n        Defaults to ``None``.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.test_dataloader","title":"<code>test_dataloader()</code>","text":"<p>Create and return the test dataloader.</p> <p>Returns:</p> Type Description <code>DataLoader[Any]</code> <p>The test dataloader.</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def test_dataloader(self) -&gt; DataLoader[Any]:\n    \"\"\"Create and return the test dataloader.\n\n    Returns:\n        The test dataloader.\n    \"\"\"\n    assert self.data_test is not None\n    return DataLoader(\n        dataset=self.data_test,\n        batch_size=self.batch_size_per_device,\n        num_workers=self.hparams[\"num_workers\"],\n        pin_memory=self.hparams[\"pin_memory\"],\n        shuffle=False,\n    )\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.train_dataloader","title":"<code>train_dataloader()</code>","text":"<p>Create and return the train dataloader.</p> <p>Returns:</p> Type Description <code>DataLoader[Any]</code> <p>The train dataloader.</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader[Any]:\n    \"\"\"Create and return the train dataloader.\n\n    Returns:\n        The train dataloader.\n    \"\"\"\n    assert self.data_train is not None\n    return DataLoader(\n        dataset=self.data_train,\n        batch_size=self.batch_size_per_device,\n        num_workers=self.hparams[\"num_workers\"],\n        pin_memory=self.hparams[\"pin_memory\"],\n        shuffle=True,\n    )\n</code></pre>"},{"location":"api/data/mnist_datamodule/#src.data.mnist_datamodule.MNISTDataModule.val_dataloader","title":"<code>val_dataloader()</code>","text":"<p>Create and return the validation dataloader.</p> <p>Returns:</p> Type Description <code>DataLoader[Any]</code> <p>The validation dataloader.</p> Source code in <code>src/data/mnist_datamodule.py</code> <pre><code>def val_dataloader(self) -&gt; DataLoader[Any]:\n    \"\"\"Create and return the validation dataloader.\n\n    Returns:\n        The validation dataloader.\n    \"\"\"\n    assert self.data_val is not None\n    return DataLoader(\n        dataset=self.data_val,\n        batch_size=self.batch_size_per_device,\n        num_workers=self.hparams[\"num_workers\"],\n        pin_memory=self.hparams[\"pin_memory\"],\n        shuffle=False,\n    )\n</code></pre>"},{"location":"api/data/polars_datamodule/","title":"Polars datamodule","text":"<p>PyTorch Lightning DataModule for loading dataset using Polars.</p>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataModule","title":"<code>PolarsDataModule</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>PyTorch Lightning DataModule for loading dataset using Polars.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>class PolarsDataModule(LightningDataModule):\n    \"\"\"PyTorch Lightning DataModule for loading dataset using Polars.\"\"\"\n\n    def __init__(\n        self, data_path: str, output_column: str, batch_size: int = 32, num_workers: int = 0, test_size: float = 0.2\n    ) -&gt; None:\n        \"\"\"Initialize the PolarsDataModule.\n\n        Args:\n            data_path: Path to the dataset.\n            output_column: Column name that contains the labels.\n            batch_size: Batch size for the dataloaders.\n            num_workers: Number of workers for the dataloaders.\n            test_size: Fraction of the dataset to be used for validation.\n        \"\"\"\n        super().__init__()\n        self.data_path = data_path\n        self.output_column = output_column\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.test_size = test_size\n        self.df: pl.DataFrame\n\n    def setup(self, stage: str = \"\") -&gt; None:\n        \"\"\"Load and split the dataset into train and validation sets.\"\"\"\n        # Load dataset using Polars\n        self.df = pl.read_csv(self.data_path)\n\n        # Split the data into train and validation sets\n        train_df, val_df = train_test_split(self.df, test_size=self.test_size, random_state=42)\n\n        self.train_dataset = PolarsDataset(pl.DataFrame(train_df), output_column=self.output_column)\n        self.val_dataset = PolarsDataset(pl.DataFrame(val_df), output_column=self.output_column)\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"Create and return the train dataloader.\"\"\"\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n\n    def val_dataloader(self) -&gt; DataLoader:\n        \"\"\"Create and return the validation dataloader.\"\"\"\n        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataModule.__init__","title":"<code>__init__(data_path, output_column, batch_size=32, num_workers=0, test_size=0.2)</code>","text":"<p>Initialize the PolarsDataModule.</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>str</code> <p>Path to the dataset.</p> required <code>output_column</code> <code>str</code> <p>Column name that contains the labels.</p> required <code>batch_size</code> <code>int</code> <p>Batch size for the dataloaders.</p> <code>32</code> <code>num_workers</code> <code>int</code> <p>Number of workers for the dataloaders.</p> <code>0</code> <code>test_size</code> <code>float</code> <p>Fraction of the dataset to be used for validation.</p> <code>0.2</code> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def __init__(\n    self, data_path: str, output_column: str, batch_size: int = 32, num_workers: int = 0, test_size: float = 0.2\n) -&gt; None:\n    \"\"\"Initialize the PolarsDataModule.\n\n    Args:\n        data_path: Path to the dataset.\n        output_column: Column name that contains the labels.\n        batch_size: Batch size for the dataloaders.\n        num_workers: Number of workers for the dataloaders.\n        test_size: Fraction of the dataset to be used for validation.\n    \"\"\"\n    super().__init__()\n    self.data_path = data_path\n    self.output_column = output_column\n    self.batch_size = batch_size\n    self.num_workers = num_workers\n    self.test_size = test_size\n    self.df: pl.DataFrame\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataModule.setup","title":"<code>setup(stage='')</code>","text":"<p>Load and split the dataset into train and validation sets.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def setup(self, stage: str = \"\") -&gt; None:\n    \"\"\"Load and split the dataset into train and validation sets.\"\"\"\n    # Load dataset using Polars\n    self.df = pl.read_csv(self.data_path)\n\n    # Split the data into train and validation sets\n    train_df, val_df = train_test_split(self.df, test_size=self.test_size, random_state=42)\n\n    self.train_dataset = PolarsDataset(pl.DataFrame(train_df), output_column=self.output_column)\n    self.val_dataset = PolarsDataset(pl.DataFrame(val_df), output_column=self.output_column)\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataModule.train_dataloader","title":"<code>train_dataloader()</code>","text":"<p>Create and return the train dataloader.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader:\n    \"\"\"Create and return the train dataloader.\"\"\"\n    return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataModule.val_dataloader","title":"<code>val_dataloader()</code>","text":"<p>Create and return the validation dataloader.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def val_dataloader(self) -&gt; DataLoader:\n    \"\"\"Create and return the validation dataloader.\"\"\"\n    return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataset","title":"<code>PolarsDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Custom PyTorch Dataset wrapping a Polars DataFrame.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>class PolarsDataset(Dataset):\n    \"\"\"Custom PyTorch Dataset wrapping a Polars DataFrame.\"\"\"\n\n    def __init__(self, df: pl.DataFrame, output_column: str) -&gt; None:\n        \"\"\"Initialize the PolarsDataset.\"\"\"\n        self.df = df\n        self.output_column = output_column\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of rows in the dataset.\"\"\"\n        return self.df.shape[0]\n\n    def __getitem__(self, idx: int) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Return the features and label for the given index.\"\"\"\n        row = self.df[idx]\n        features = torch.tensor([val for col, val in row.item() if col != self.output_column], dtype=torch.float32)\n        label = torch.tensor(row[self.output_column], dtype=torch.long)\n        return features, label\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataset.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the features and label for the given index.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Return the features and label for the given index.\"\"\"\n    row = self.df[idx]\n    features = torch.tensor([val for col, val in row.item() if col != self.output_column], dtype=torch.float32)\n    label = torch.tensor(row[self.output_column], dtype=torch.long)\n    return features, label\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataset.__init__","title":"<code>__init__(df, output_column)</code>","text":"<p>Initialize the PolarsDataset.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def __init__(self, df: pl.DataFrame, output_column: str) -&gt; None:\n    \"\"\"Initialize the PolarsDataset.\"\"\"\n    self.df = df\n    self.output_column = output_column\n</code></pre>"},{"location":"api/data/polars_datamodule/#src.data.polars_datamodule.PolarsDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of rows in the dataset.</p> Source code in <code>src/data/polars_datamodule.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of rows in the dataset.\"\"\"\n    return self.df.shape[0]\n</code></pre>"},{"location":"api/models/mnist_module/","title":"Mnist module","text":"<p>Mnist simple model.</p>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule","title":"<code>MNISTLitModule</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Example of a <code>LightningModule</code> for MNIST classification.</p> <p>A <code>LightningModule</code> implements 8 key methods:</p> <pre><code>def __init__(self):\n# Define initialization code here.\n\ndef setup(self, stage):\n# Things to setup before each stage, 'fit', 'validate', 'test', 'predict'.\n# This hook is called on every process when using DDP.\n\ndef training_step(self, batch, batch_idx):\n# The complete training step.\n\ndef validation_step(self, batch, batch_idx):\n# The complete validation step.\n\ndef test_step(self, batch, batch_idx):\n# The complete test step.\n\ndef predict_step(self, batch, batch_idx):\n# The complete predict step.\n\ndef configure_optimizers(self):\n# Define and configure optimizers and LR schedulers.\n</code></pre> Docs <p>https://lightning.ai/docs/pytorch/latest/common/lightning_module.html</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>class MNISTLitModule(LightningModule):\n    \"\"\"Example of a `LightningModule` for MNIST classification.\n\n    A `LightningModule` implements 8 key methods:\n\n    ```python\n    def __init__(self):\n    # Define initialization code here.\n\n    def setup(self, stage):\n    # Things to setup before each stage, 'fit', 'validate', 'test', 'predict'.\n    # This hook is called on every process when using DDP.\n\n    def training_step(self, batch, batch_idx):\n    # The complete training step.\n\n    def validation_step(self, batch, batch_idx):\n    # The complete validation step.\n\n    def test_step(self, batch, batch_idx):\n    # The complete test step.\n\n    def predict_step(self, batch, batch_idx):\n    # The complete predict step.\n\n    def configure_optimizers(self):\n    # Define and configure optimizers and LR schedulers.\n    ```\n\n    Docs:\n        https://lightning.ai/docs/pytorch/latest/common/lightning_module.html\n    \"\"\"\n\n    def __init__(\n        self,\n        net: torch.nn.Module,\n        optimizer: torch.optim.Optimizer,\n        scheduler: torch.optim.lr_scheduler._LRScheduler | None,\n        compile_model: bool,\n    ) -&gt; None:\n        \"\"\"Initialize a `MNISTLitModule`.\n\n        Args:\n            net: The model to train.\n            optimizer: The optimizer to use for training.\n            scheduler: The learning rate scheduler to use for training.\n            compile_model: Whether or not compile the model.\n        \"\"\"\n        super().__init__()\n\n        # this line allows to access init params with 'self.hparams' attribute\n        # also ensures init params will be stored in ckpt\n        self.save_hyperparameters(logger=False)\n\n        self.net = net\n\n        # loss function\n        self.criterion = torch.nn.CrossEntropyLoss()\n\n        # metric objects for calculating and averaging accuracy across batches\n        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n        self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n        self.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n\n        # for averaging loss across batches\n        self.train_loss = MeanMetric()\n        self.val_loss = MeanMetric()\n        self.test_loss = MeanMetric()\n\n        # for tracking best so far validation accuracy\n        self.val_acc_best = MaxMetric()\n\n    @typechecked\n    def forward(self, x: TensorType[Batch, 1, 28, 28]) -&gt; TensorType[Batch, 10]:  # ty\n        \"\"\"Perform a forward pass through the model.\n\n        Args:\n            x: A tensor of shape (batch_size, 1, 28, 28) representing the MNIST images.\n\n        Returns:\n            A tensor of shape (batch_size, 10) representing the logits for each class.\n        \"\"\"\n        return self.net(x)\n\n    def on_train_start(self) -&gt; None:\n        \"\"\"Lightning hook that is called when training begins.\"\"\"\n        # by default lightning executes validation step sanity checks before training starts,\n        # so it's worth to make sure validation metrics don't store results from these checks\n        self.val_loss.reset()\n        self.val_acc.reset()\n        self.val_acc_best.reset()\n\n    @typechecked\n    def model_step(\n        self, x: TensorType[Batch, 1, 28, 28], y: TensorType[Batch]\n    ) -&gt; tuple[TensorType[()], TensorType[()], TensorType[()]]:\n        \"\"\"Perform a single model step.\n\n        Args:\n            x: Tensor of shape [batch, 1, 28, 28] representing the images.\n            y: Tensor of shape [batch] representing the classes.\n\n        Returns:\n            A tuple containing:\n                - loss: A tensor of shape (batch_size,)\n                - preds: A tensor of predicted class indices (batch_size,)\n                - targets: A tensor of true class labels (batch_size,)\n        \"\"\"\n        logits = self.forward(x)\n        loss = self.criterion(logits, y)\n        preds = torch.argmax(logits, dim=1)\n        return loss, preds, y\n\n    @typechecked\n    def training_step(self, batch: Any, batch_idx: int) -&gt; TensorType[()]:\n        \"\"\"Perform a single training step.\n\n        Args:\n            batch: A tuple containing input images and target labels.\n            batch_idx: The index of the current batch.\n\n        Returns:\n            A scalar loss tensor.\n        \"\"\"\n        x, y = batch\n        loss, preds, targets = self.model_step(x, y)\n        self.train_loss(loss)\n        self.train_acc(preds, targets)\n        self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n\n    def on_train_epoch_end(self) -&gt; None:\n        \"\"\"Lightning hook that is called when a training epoch ends.\"\"\"\n        pass\n\n    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -&gt; None:\n        \"\"\"Perform a single validation step on a batch of data from the validation set.\n\n        Args:\n            batch: A batch of data (a tuple) containing the input tensor of images and target\n                labels.\n            batch_idx: The index of the current batch.\n        \"\"\"\n        x, y = batch\n        loss, preds, targets = self.model_step(x, y)\n\n        # update and log metrics\n        self.val_loss(loss)\n        self.val_acc(preds, targets)\n        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"val/acc\", self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n\n    def on_validation_epoch_end(self) -&gt; None:\n        \"\"\"Lightning hook that is called when a validation epoch ends.\"\"\"\n        # get current val acc\n        acc = self.val_acc.compute()  # type: ignore\n        self.val_acc_best(acc)  # update best so far val acc\n        # log `val_acc_best` as a value through `.compute()` method, instead of as a metric object\n        # otherwise metric would be reset by lightning after each epoch\n        self.log(\"val/acc_best\", self.val_acc_best.compute(), sync_dist=True, prog_bar=True)\n\n    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -&gt; None:\n        \"\"\"Perform a single test step on a batch of data from the test set.\n\n        Args:\n            batch: A batch of data (a tuple) containing the input tensor of images and target\n                labels.\n            batch_idx: The index of the current batch.\n        \"\"\"\n        x, y = batch\n        loss, preds, targets = self.model_step(x, y)\n\n        # update and log metrics\n        self.test_loss(loss)\n        self.test_acc(preds, targets)\n        self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log(\"test/acc\", self.test_acc, on_step=False, on_epoch=True, prog_bar=True)\n\n    def on_test_epoch_end(self) -&gt; None:\n        \"\"\"Lightning hook that is called when a test epoch ends.\"\"\"\n        pass\n\n    def setup(self, stage: str) -&gt; None:\n        \"\"\"Lightning hook that is called at the beginning of fit (train + validate), validate, test, or predict.\n\n        This is a good hook when you need to build models dynamically or adjust something about\n        them. This hook is called on every process when using DDP.\n\n        Args:\n            stage: Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n        \"\"\"\n        if self.hparams[\"compile_model\"] and stage == \"fit\":\n            self.net = torch.compile(self.net)  # type: ignore\n\n    def configure_optimizers(self) -&gt; dict[str, Any]:  # type: ignore\n        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n\n        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n\n        Examples:\n            https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers\n\n        Returns:\n            A dict containing the configured optimizers and learning-rate schedulers to be used for training.\n        \"\"\"\n        assert self.trainer.model is not None, \"Model is not compiled yet.\"\n        optimizer = self.hparams[\"optimizer\"](params=self.trainer.model.parameters())\n        if self.hparams[\"scheduler\"] is not None:\n            scheduler = self.hparams[\"scheduler\"](optimizer=optimizer)\n            return {\n                \"optimizer\": optimizer,\n                \"lr_scheduler\": {\n                    \"scheduler\": scheduler,\n                    \"monitor\": \"val/loss\",\n                    \"interval\": \"epoch\",\n                    \"frequency\": 1,\n                },\n            }\n        return {\"optimizer\": optimizer}\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.__init__","title":"<code>__init__(net, optimizer, scheduler, compile_model)</code>","text":"<p>Initialize a <code>MNISTLitModule</code>.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Module</code> <p>The model to train.</p> required <code>optimizer</code> <code>Optimizer</code> <p>The optimizer to use for training.</p> required <code>scheduler</code> <code>_LRScheduler | None</code> <p>The learning rate scheduler to use for training.</p> required <code>compile_model</code> <code>bool</code> <p>Whether or not compile the model.</p> required Source code in <code>src/models/mnist_module.py</code> <pre><code>def __init__(\n    self,\n    net: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    scheduler: torch.optim.lr_scheduler._LRScheduler | None,\n    compile_model: bool,\n) -&gt; None:\n    \"\"\"Initialize a `MNISTLitModule`.\n\n    Args:\n        net: The model to train.\n        optimizer: The optimizer to use for training.\n        scheduler: The learning rate scheduler to use for training.\n        compile_model: Whether or not compile the model.\n    \"\"\"\n    super().__init__()\n\n    # this line allows to access init params with 'self.hparams' attribute\n    # also ensures init params will be stored in ckpt\n    self.save_hyperparameters(logger=False)\n\n    self.net = net\n\n    # loss function\n    self.criterion = torch.nn.CrossEntropyLoss()\n\n    # metric objects for calculating and averaging accuracy across batches\n    self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n    self.val_acc = Accuracy(task=\"multiclass\", num_classes=10)\n    self.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n\n    # for averaging loss across batches\n    self.train_loss = MeanMetric()\n    self.val_loss = MeanMetric()\n    self.test_loss = MeanMetric()\n\n    # for tracking best so far validation accuracy\n    self.val_acc_best = MaxMetric()\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Choose what optimizers and learning-rate schedulers to use in your optimization.</p> <p>Normally you'd need one. But in the case of GANs or similar you might have multiple.</p> <p>Examples:</p> <p>https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dict containing the configured optimizers and learning-rate schedulers to be used for training.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>def configure_optimizers(self) -&gt; dict[str, Any]:  # type: ignore\n    \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n\n    Normally you'd need one. But in the case of GANs or similar you might have multiple.\n\n    Examples:\n        https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers\n\n    Returns:\n        A dict containing the configured optimizers and learning-rate schedulers to be used for training.\n    \"\"\"\n    assert self.trainer.model is not None, \"Model is not compiled yet.\"\n    optimizer = self.hparams[\"optimizer\"](params=self.trainer.model.parameters())\n    if self.hparams[\"scheduler\"] is not None:\n        scheduler = self.hparams[\"scheduler\"](optimizer=optimizer)\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"monitor\": \"val/loss\",\n                \"interval\": \"epoch\",\n                \"frequency\": 1,\n            },\n        }\n    return {\"optimizer\": optimizer}\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.forward","title":"<code>forward(x)</code>","text":"<p>Perform a forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>TensorType[Batch, 1, 28, 28]</code> <p>A tensor of shape (batch_size, 1, 28, 28) representing the MNIST images.</p> required <p>Returns:</p> Type Description <code>TensorType[Batch, 10]</code> <p>A tensor of shape (batch_size, 10) representing the logits for each class.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>@typechecked\ndef forward(self, x: TensorType[Batch, 1, 28, 28]) -&gt; TensorType[Batch, 10]:  # ty\n    \"\"\"Perform a forward pass through the model.\n\n    Args:\n        x: A tensor of shape (batch_size, 1, 28, 28) representing the MNIST images.\n\n    Returns:\n        A tensor of shape (batch_size, 10) representing the logits for each class.\n    \"\"\"\n    return self.net(x)\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.model_step","title":"<code>model_step(x, y)</code>","text":"<p>Perform a single model step.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>TensorType[Batch, 1, 28, 28]</code> <p>Tensor of shape [batch, 1, 28, 28] representing the images.</p> required <code>y</code> <code>TensorType[Batch]</code> <p>Tensor of shape [batch] representing the classes.</p> required <p>Returns:</p> Type Description <code>tuple[TensorType[], TensorType[], TensorType[]]</code> <p>A tuple containing: - loss: A tensor of shape (batch_size,) - preds: A tensor of predicted class indices (batch_size,) - targets: A tensor of true class labels (batch_size,)</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>@typechecked\ndef model_step(\n    self, x: TensorType[Batch, 1, 28, 28], y: TensorType[Batch]\n) -&gt; tuple[TensorType[()], TensorType[()], TensorType[()]]:\n    \"\"\"Perform a single model step.\n\n    Args:\n        x: Tensor of shape [batch, 1, 28, 28] representing the images.\n        y: Tensor of shape [batch] representing the classes.\n\n    Returns:\n        A tuple containing:\n            - loss: A tensor of shape (batch_size,)\n            - preds: A tensor of predicted class indices (batch_size,)\n            - targets: A tensor of true class labels (batch_size,)\n    \"\"\"\n    logits = self.forward(x)\n    loss = self.criterion(logits, y)\n    preds = torch.argmax(logits, dim=1)\n    return loss, preds, y\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.on_test_epoch_end","title":"<code>on_test_epoch_end()</code>","text":"<p>Lightning hook that is called when a test epoch ends.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>def on_test_epoch_end(self) -&gt; None:\n    \"\"\"Lightning hook that is called when a test epoch ends.\"\"\"\n    pass\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.on_train_epoch_end","title":"<code>on_train_epoch_end()</code>","text":"<p>Lightning hook that is called when a training epoch ends.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>def on_train_epoch_end(self) -&gt; None:\n    \"\"\"Lightning hook that is called when a training epoch ends.\"\"\"\n    pass\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.on_train_start","title":"<code>on_train_start()</code>","text":"<p>Lightning hook that is called when training begins.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>def on_train_start(self) -&gt; None:\n    \"\"\"Lightning hook that is called when training begins.\"\"\"\n    # by default lightning executes validation step sanity checks before training starts,\n    # so it's worth to make sure validation metrics don't store results from these checks\n    self.val_loss.reset()\n    self.val_acc.reset()\n    self.val_acc_best.reset()\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.on_validation_epoch_end","title":"<code>on_validation_epoch_end()</code>","text":"<p>Lightning hook that is called when a validation epoch ends.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>def on_validation_epoch_end(self) -&gt; None:\n    \"\"\"Lightning hook that is called when a validation epoch ends.\"\"\"\n    # get current val acc\n    acc = self.val_acc.compute()  # type: ignore\n    self.val_acc_best(acc)  # update best so far val acc\n    # log `val_acc_best` as a value through `.compute()` method, instead of as a metric object\n    # otherwise metric would be reset by lightning after each epoch\n    self.log(\"val/acc_best\", self.val_acc_best.compute(), sync_dist=True, prog_bar=True)\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.setup","title":"<code>setup(stage)</code>","text":"<p>Lightning hook that is called at the beginning of fit (train + validate), validate, test, or predict.</p> <p>This is a good hook when you need to build models dynamically or adjust something about them. This hook is called on every process when using DDP.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>str</code> <p>Either <code>\"fit\"</code>, <code>\"validate\"</code>, <code>\"test\"</code>, or <code>\"predict\"</code>.</p> required Source code in <code>src/models/mnist_module.py</code> <pre><code>def setup(self, stage: str) -&gt; None:\n    \"\"\"Lightning hook that is called at the beginning of fit (train + validate), validate, test, or predict.\n\n    This is a good hook when you need to build models dynamically or adjust something about\n    them. This hook is called on every process when using DDP.\n\n    Args:\n        stage: Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n    \"\"\"\n    if self.hparams[\"compile_model\"] and stage == \"fit\":\n        self.net = torch.compile(self.net)  # type: ignore\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.test_step","title":"<code>test_step(batch, batch_idx)</code>","text":"<p>Perform a single test step on a batch of data from the test set.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple[Tensor, Tensor]</code> <p>A batch of data (a tuple) containing the input tensor of images and target labels.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the current batch.</p> required Source code in <code>src/models/mnist_module.py</code> <pre><code>def test_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -&gt; None:\n    \"\"\"Perform a single test step on a batch of data from the test set.\n\n    Args:\n        batch: A batch of data (a tuple) containing the input tensor of images and target\n            labels.\n        batch_idx: The index of the current batch.\n    \"\"\"\n    x, y = batch\n    loss, preds, targets = self.model_step(x, y)\n\n    # update and log metrics\n    self.test_loss(loss)\n    self.test_acc(preds, targets)\n    self.log(\"test/loss\", self.test_loss, on_step=False, on_epoch=True, prog_bar=True)\n    self.log(\"test/acc\", self.test_acc, on_step=False, on_epoch=True, prog_bar=True)\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Perform a single training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Any</code> <p>A tuple containing input images and target labels.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the current batch.</p> required <p>Returns:</p> Type Description <code>TensorType[]</code> <p>A scalar loss tensor.</p> Source code in <code>src/models/mnist_module.py</code> <pre><code>@typechecked\ndef training_step(self, batch: Any, batch_idx: int) -&gt; TensorType[()]:\n    \"\"\"Perform a single training step.\n\n    Args:\n        batch: A tuple containing input images and target labels.\n        batch_idx: The index of the current batch.\n\n    Returns:\n        A scalar loss tensor.\n    \"\"\"\n    x, y = batch\n    loss, preds, targets = self.model_step(x, y)\n    self.train_loss(loss)\n    self.train_acc(preds, targets)\n    self.log(\"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True)\n    self.log(\"train/acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n    return loss\n</code></pre>"},{"location":"api/models/mnist_module/#src.models.mnist_module.MNISTLitModule.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Perform a single validation step on a batch of data from the validation set.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>tuple[Tensor, Tensor]</code> <p>A batch of data (a tuple) containing the input tensor of images and target labels.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the current batch.</p> required Source code in <code>src/models/mnist_module.py</code> <pre><code>def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -&gt; None:\n    \"\"\"Perform a single validation step on a batch of data from the validation set.\n\n    Args:\n        batch: A batch of data (a tuple) containing the input tensor of images and target\n            labels.\n        batch_idx: The index of the current batch.\n    \"\"\"\n    x, y = batch\n    loss, preds, targets = self.model_step(x, y)\n\n    # update and log metrics\n    self.val_loss(loss)\n    self.val_acc(preds, targets)\n    self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n    self.log(\"val/acc\", self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n</code></pre>"},{"location":"api/models/components/simple_dense_net/","title":"Simple dense net","text":"<p>Simple dense neural network.</p>"},{"location":"api/models/components/simple_dense_net/#src.models.components.simple_dense_net.SimpleDenseNet","title":"<code>SimpleDenseNet</code>","text":"<p>               Bases: <code>Module</code></p> <p>A simple fully-connected neural net for computing predictions.</p> Source code in <code>src/models/components/simple_dense_net.py</code> <pre><code>class SimpleDenseNet(nn.Module):\n    \"\"\"A simple fully-connected neural net for computing predictions.\"\"\"\n\n    def __init__(\n        self,\n        input_size: int = 784,\n        lin1_size: int = 256,\n        lin2_size: int = 256,\n        lin3_size: int = 256,\n        output_size: int = 10,\n    ) -&gt; None:\n        \"\"\"Initialize a `SimpleDenseNet` module.\n\n        Args:\n            input_size: The number of input features.\n            lin1_size: The number of output features of the first linear layer.\n            lin2_size: The number of output features of the second linear layer.\n            lin3_size: The number of output features of the third linear layer.\n            output_size: The number of output features of the final linear layer.\n        \"\"\"\n        super().__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(input_size, lin1_size),\n            nn.BatchNorm1d(lin1_size),\n            nn.ReLU(),\n            nn.Linear(lin1_size, lin2_size),\n            nn.BatchNorm1d(lin2_size),\n            nn.ReLU(),\n            nn.Linear(lin2_size, lin3_size),\n            nn.BatchNorm1d(lin3_size),\n            nn.ReLU(),\n            nn.Linear(lin3_size, output_size),\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Perform a single forward pass through the network.\n\n        Args:\n            x: The input tensor.\n\n        Returns:\n            A tensor of predictions.\n        \"\"\"\n        batch_size, channels, width, height = x.size()\n\n        # (batch, 1, width, height) -&gt; (batch, 1*width*height)\n        x = x.view(batch_size, -1)\n\n        return torch.tensor(self.model(x))\n</code></pre>"},{"location":"api/models/components/simple_dense_net/#src.models.components.simple_dense_net.SimpleDenseNet.__init__","title":"<code>__init__(input_size=784, lin1_size=256, lin2_size=256, lin3_size=256, output_size=10)</code>","text":"<p>Initialize a <code>SimpleDenseNet</code> module.</p> <p>Parameters:</p> Name Type Description Default <code>input_size</code> <code>int</code> <p>The number of input features.</p> <code>784</code> <code>lin1_size</code> <code>int</code> <p>The number of output features of the first linear layer.</p> <code>256</code> <code>lin2_size</code> <code>int</code> <p>The number of output features of the second linear layer.</p> <code>256</code> <code>lin3_size</code> <code>int</code> <p>The number of output features of the third linear layer.</p> <code>256</code> <code>output_size</code> <code>int</code> <p>The number of output features of the final linear layer.</p> <code>10</code> Source code in <code>src/models/components/simple_dense_net.py</code> <pre><code>def __init__(\n    self,\n    input_size: int = 784,\n    lin1_size: int = 256,\n    lin2_size: int = 256,\n    lin3_size: int = 256,\n    output_size: int = 10,\n) -&gt; None:\n    \"\"\"Initialize a `SimpleDenseNet` module.\n\n    Args:\n        input_size: The number of input features.\n        lin1_size: The number of output features of the first linear layer.\n        lin2_size: The number of output features of the second linear layer.\n        lin3_size: The number of output features of the third linear layer.\n        output_size: The number of output features of the final linear layer.\n    \"\"\"\n    super().__init__()\n\n    self.model = nn.Sequential(\n        nn.Linear(input_size, lin1_size),\n        nn.BatchNorm1d(lin1_size),\n        nn.ReLU(),\n        nn.Linear(lin1_size, lin2_size),\n        nn.BatchNorm1d(lin2_size),\n        nn.ReLU(),\n        nn.Linear(lin2_size, lin3_size),\n        nn.BatchNorm1d(lin3_size),\n        nn.ReLU(),\n        nn.Linear(lin3_size, output_size),\n    )\n</code></pre>"},{"location":"api/models/components/simple_dense_net/#src.models.components.simple_dense_net.SimpleDenseNet.forward","title":"<code>forward(x)</code>","text":"<p>Perform a single forward pass through the network.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of predictions.</p> Source code in <code>src/models/components/simple_dense_net.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Perform a single forward pass through the network.\n\n    Args:\n        x: The input tensor.\n\n    Returns:\n        A tensor of predictions.\n    \"\"\"\n    batch_size, channels, width, height = x.size()\n\n    # (batch, 1, width, height) -&gt; (batch, 1*width*height)\n    x = x.view(batch_size, -1)\n\n    return torch.tensor(self.model(x))\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/","title":"Mnist serve","text":"<p>This is an example of a LitServe api for the Mnist LightningModule.</p>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI","title":"<code>MNISTServeAPI</code>","text":"<p>               Bases: <code>LitAPI</code></p> <p>LitServe API for serving the MNIST model.</p> Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>class MNISTServeAPI(ls.LitAPI):\n    \"\"\"LitServe API for serving the MNIST model.\"\"\"\n\n    def __init__(self, model_class: lightning.pytorch.LightningModule, checkpoint_path: str):\n        \"\"\"Initialize the MNISTServeAPI.\n\n        Args:\n            model_class: The LightningModule class to serve.\n            checkpoint_path: The path to the model checkpoint.\n        \"\"\"\n        self.checkpoint_path = checkpoint_path\n        self.model_class = model_class\n\n    def setup(self, device: str | torch.device) -&gt; None:\n        \"\"\"Setup is called once at startup.\n\n        Load the model, set the device, and prepare any other necessary components.\n        \"\"\"\n        # Load the trained MNIST model (ensure model weights are loaded properly here)\n        self.model = self.model_class.load_from_checkpoint(self.checkpoint_path)\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(device)  # Move the model to the appropriate device (CPU or GPU)\n        self.model.eval()  # Set the model to evaluation mode\n\n        # Define transforms that match the training data processing pipeline\n        self.transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n\n    def decode_request(self, request: dict) -&gt; torch.Tensor:\n        \"\"\"Decode the incoming request and prepare the input for the model.\"\"\"\n        # Convert the request payload into a tensor for model input\n        image_data = request[\"image\"]\n        # Ensure that the image is a tensor of shape [1, 28, 28] (MNIST image dimensions)\n        image_tensor = torch.tensor(image_data).unsqueeze(0)  # Add a batch dimension\n        return cast(torch.Tensor, self.transforms(image_tensor))  # Apply the necessary transformations\n\n    def predict(self, x: torch.Tensor) -&gt; dict[str, float | int]:\n        \"\"\"Run inference using the MNIST model and return the prediction.\"\"\"\n        # Forward pass through the model\n        with torch.no_grad():\n            logits = self.model(x.unsqueeze(0))  # Add batch dimension for inference\n            preds = torch.argmax(logits, dim=1)  # Get the predicted class\n        return {\"prediction\": preds.item()}  # Return the prediction as a dictionary\n\n    def encode_response(self, output: dict) -&gt; dict[str, float | int]:\n        \"\"\"Encode the model's output into a response payload.\"\"\"\n        # Simply pass the output as the response\n        return {\"predicted_class\": output[\"prediction\"]}\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI.__init__","title":"<code>__init__(model_class, checkpoint_path)</code>","text":"<p>Initialize the MNISTServeAPI.</p> <p>Parameters:</p> Name Type Description Default <code>model_class</code> <code>LightningModule</code> <p>The LightningModule class to serve.</p> required <code>checkpoint_path</code> <code>str</code> <p>The path to the model checkpoint.</p> required Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>def __init__(self, model_class: lightning.pytorch.LightningModule, checkpoint_path: str):\n    \"\"\"Initialize the MNISTServeAPI.\n\n    Args:\n        model_class: The LightningModule class to serve.\n        checkpoint_path: The path to the model checkpoint.\n    \"\"\"\n    self.checkpoint_path = checkpoint_path\n    self.model_class = model_class\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI.decode_request","title":"<code>decode_request(request)</code>","text":"<p>Decode the incoming request and prepare the input for the model.</p> Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>def decode_request(self, request: dict) -&gt; torch.Tensor:\n    \"\"\"Decode the incoming request and prepare the input for the model.\"\"\"\n    # Convert the request payload into a tensor for model input\n    image_data = request[\"image\"]\n    # Ensure that the image is a tensor of shape [1, 28, 28] (MNIST image dimensions)\n    image_tensor = torch.tensor(image_data).unsqueeze(0)  # Add a batch dimension\n    return cast(torch.Tensor, self.transforms(image_tensor))  # Apply the necessary transformations\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI.encode_response","title":"<code>encode_response(output)</code>","text":"<p>Encode the model's output into a response payload.</p> Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>def encode_response(self, output: dict) -&gt; dict[str, float | int]:\n    \"\"\"Encode the model's output into a response payload.\"\"\"\n    # Simply pass the output as the response\n    return {\"predicted_class\": output[\"prediction\"]}\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI.predict","title":"<code>predict(x)</code>","text":"<p>Run inference using the MNIST model and return the prediction.</p> Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>def predict(self, x: torch.Tensor) -&gt; dict[str, float | int]:\n    \"\"\"Run inference using the MNIST model and return the prediction.\"\"\"\n    # Forward pass through the model\n    with torch.no_grad():\n        logits = self.model(x.unsqueeze(0))  # Add batch dimension for inference\n        preds = torch.argmax(logits, dim=1)  # Get the predicted class\n    return {\"prediction\": preds.item()}  # Return the prediction as a dictionary\n</code></pre>"},{"location":"api/serve_apis/mnist_serve/#src.serve_apis.mnist_serve.MNISTServeAPI.setup","title":"<code>setup(device)</code>","text":"<p>Setup is called once at startup.</p> <p>Load the model, set the device, and prepare any other necessary components.</p> Source code in <code>src/serve_apis/mnist_serve.py</code> <pre><code>def setup(self, device: str | torch.device) -&gt; None:\n    \"\"\"Setup is called once at startup.\n\n    Load the model, set the device, and prepare any other necessary components.\n    \"\"\"\n    # Load the trained MNIST model (ensure model weights are loaded properly here)\n    self.model = self.model_class.load_from_checkpoint(self.checkpoint_path)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    self.model.to(device)  # Move the model to the appropriate device (CPU or GPU)\n    self.model.eval()  # Set the model to evaluation mode\n\n    # Define transforms that match the training data processing pipeline\n    self.transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n</code></pre>"},{"location":"api/utils/download_utils/","title":"Download utils","text":"<p>Utility functions aimed at downloading any data from external sources.</p>"},{"location":"api/utils/download_utils/#src.utils.download_utils.download_cloud_directory","title":"<code>download_cloud_directory(cloud_directory, output_folder, cloud='gs')</code>","text":"<p>Download a given cloud directory.</p> <p>Parameters:</p> Name Type Description Default <code>cloud_directory</code> <code>str</code> <p>for example gs://bucket-name/path/to/directory</p> required <code>output_folder</code> <code>str</code> <p>where the data downloaded will be stored (ideally data/ folder)</p> required <code>cloud</code> <code>str</code> <p>the cloud provider, currently only \"gs\" is supported</p> <code>'gs'</code> Source code in <code>src/utils/download_utils.py</code> <pre><code>def download_cloud_directory(cloud_directory: str, output_folder: str, cloud: str = \"gs\") -&gt; None:\n    \"\"\"Download a given cloud directory.\n\n    Args:\n        cloud_directory: for example gs://bucket-name/path/to/directory\n        output_folder: where the data downloaded will be stored (ideally data/ folder)\n        cloud: the cloud provider, currently only \"gs\" is supported\n    \"\"\"\n    cloudpathlib.Path(cloud_directory).download_to(output_folder)\n</code></pre>"},{"location":"api/utils/download_utils/#src.utils.download_utils.download_kaggle_dataset","title":"<code>download_kaggle_dataset(dataset_name, output_folder)</code>","text":"<p>Download a given Kaggle dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>for example googleai/pfam-seed-random-split</p> required <code>output_folder</code> <code>str</code> <p>where the data downloaded will be stored (ideally data/ folder)</p> required Source code in <code>src/utils/download_utils.py</code> <pre><code>def download_kaggle_dataset(dataset_name: str, output_folder: str) -&gt; None:\n    \"\"\"Download a given Kaggle dataset.\n\n    Args:\n        dataset_name: for example googleai/pfam-seed-random-split\n        output_folder: where the data downloaded will be stored (ideally data/ folder)\n    \"\"\"\n    from kaggle.api.kaggle_api_extended import KaggleApi\n\n    api = KaggleApi()\n    log.info(\"Authenticating to Kaggle API\")\n    api.authenticate()\n    log.info(\"Downloading dataset\")\n    api.dataset_download_files(dataset_name, path=output_folder, unzip=True, quiet=False)\n    log.info(\"Download successful\")\n</code></pre>"},{"location":"api/utils/instantiators/","title":"Instantiators","text":"<p>Module to instantiate different objects types.</p>"},{"location":"api/utils/instantiators/#src.utils.instantiators.instantiate_callbacks","title":"<code>instantiate_callbacks(callbacks_cfg)</code>","text":"<p>Instantiates callbacks from config.</p> <p>:param callbacks_cfg: A DictConfig object containing callback configurations. :return: A list of instantiated callbacks.</p> Source code in <code>src/utils/instantiators.py</code> <pre><code>def instantiate_callbacks(callbacks_cfg: DictConfig) -&gt; list[Callback]:\n    \"\"\"Instantiates callbacks from config.\n\n    :param callbacks_cfg: A DictConfig object containing callback configurations.\n    :return: A list of instantiated callbacks.\n    \"\"\"\n    callbacks: list[Callback] = []\n\n    if not callbacks_cfg:\n        log.warning(\"No callback configs found! Skipping..\")\n        return callbacks\n\n    if not isinstance(callbacks_cfg, DictConfig):\n        raise TypeError(\"Callbacks config must be a DictConfig!\")  # noqa: TRY003\n\n    for _, cb_conf in callbacks_cfg.items():\n        if isinstance(cb_conf, DictConfig) and \"_target_\" in cb_conf:\n            log.info(f\"Instantiating callback &lt;{cb_conf._target_}&gt;\")\n            callbacks.append(hydra.utils.instantiate(cb_conf))\n\n    return callbacks\n</code></pre>"},{"location":"api/utils/instantiators/#src.utils.instantiators.instantiate_loggers","title":"<code>instantiate_loggers(logger_cfg)</code>","text":"<p>Instantiates loggers from config.</p> <p>:param logger_cfg: A DictConfig object containing logger configurations. :return: A list of instantiated loggers.</p> Source code in <code>src/utils/instantiators.py</code> <pre><code>def instantiate_loggers(logger_cfg: DictConfig) -&gt; list[Logger]:\n    \"\"\"Instantiates loggers from config.\n\n    :param logger_cfg: A DictConfig object containing logger configurations.\n    :return: A list of instantiated loggers.\n    \"\"\"\n    logger: list[Logger] = []\n\n    if not logger_cfg:\n        log.warning(\"No logger configs found! Skipping...\")\n        return logger\n\n    if not isinstance(logger_cfg, DictConfig):\n        raise TypeError(\"Logger config must be a DictConfig!\")  # noqa: TRY003\n\n    for _, lg_conf in logger_cfg.items():\n        if isinstance(lg_conf, DictConfig) and \"_target_\" in lg_conf:\n            log.info(f\"Instantiating logger &lt;{lg_conf._target_}&gt;\")\n            logger.append(hydra.utils.instantiate(lg_conf))\n\n    return logger\n</code></pre>"},{"location":"api/utils/logging_utils/","title":"Logging utils","text":"<p>Logging utility instantiator.</p>"},{"location":"api/utils/logging_utils/#src.utils.logging_utils.log_hyperparameters","title":"<code>log_hyperparameters(object_dict)</code>","text":"<p>Controls which config parts are saved by Lightning loggers.</p> <p>Additionally saves number of model parameters.</p> <p>Parameters:</p> Name Type Description Default <code>object_dict</code> <code>dict[str, Any]</code> <p>A dictionary containing the following objects: cfg, model, trainer.</p> required Source code in <code>src/utils/logging_utils.py</code> <pre><code>@rank_zero_only\ndef log_hyperparameters(object_dict: dict[str, Any]) -&gt; None:\n    \"\"\"Controls which config parts are saved by Lightning loggers.\n\n    Additionally saves number of model parameters.\n\n    Args:\n        object_dict: A dictionary containing the following objects: cfg, model, trainer.\n    \"\"\"\n    hparams: dict = {}\n\n    # Convert OmegaConf to dict and explicitly type it\n    cfg = cast(dict[str, Any], OmegaConf.to_container(object_dict[\"cfg\"]))\n    model = object_dict[\"model\"]\n    trainer = object_dict[\"trainer\"]\n\n    if not trainer.logger:\n        log.warning(\"Logger not found! Skipping hyperparameter logging...\")\n        return\n\n    assert hparams is not None\n    assert isinstance(hparams, dict)\n\n    # Add model parameters\n    hparams[\"model\"] = cfg[\"model\"]\n\n    # Save number of model parameters\n    hparams[\"model/params/total\"] = sum(p.numel() for p in model.parameters())\n    hparams[\"model/params/trainable\"] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    hparams[\"model/params/non_trainable\"] = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n\n    # Add other config sections\n    hparams[\"data\"] = cfg[\"data\"]\n    hparams[\"trainer\"] = cfg[\"trainer\"]\n\n    # Use safer access methods for optional fields\n    if \"callbacks\" in cfg:\n        hparams[\"callbacks\"] = cfg[\"callbacks\"]\n    if \"extras\" in cfg:\n        hparams[\"extras\"] = cfg[\"extras\"]\n    if \"task_name\" in cfg:\n        hparams[\"task_name\"] = cfg[\"task_name\"]\n    if \"tags\" in cfg:\n        hparams[\"tags\"] = cfg[\"tags\"]\n    if \"ckpt_path\" in cfg:\n        hparams[\"ckpt_path\"] = cfg[\"ckpt_path\"]\n    if \"seed\" in cfg:\n        hparams[\"seed\"] = cfg[\"seed\"]\n\n    hparams[\"execution_command\"] = f\"python {' '.join(sys.argv)}\"\n\n    # Send hparams to all loggers\n    for logger in trainer.loggers:\n        logger.log_hyperparams(hparams)\n</code></pre>"},{"location":"api/utils/pylogger/","title":"Pylogger","text":"<p>Code for logging on multi-GPU-friendly.</p>"},{"location":"api/utils/pylogger/#src.utils.pylogger.RankedLogger","title":"<code>RankedLogger</code>","text":"<p>               Bases: <code>LoggerAdapter</code></p> <p>A multi-GPU-friendly python command line logger.</p> Source code in <code>src/utils/pylogger.py</code> <pre><code>class RankedLogger(logging.LoggerAdapter):\n    \"\"\"A multi-GPU-friendly python command line logger.\"\"\"\n\n    def __init__(\n        self,\n        name: str = __name__,\n        rank_zero_only: bool = False,\n        extra: Mapping[str, object] | None = None,\n    ) -&gt; None:\n        \"\"\"Initializes a multi-GPU-friendly python command line logger that logs.\n\n        On all processes with their rank prefixed in the log message.\n\n        Args:\n            name: The name of the logger. Default is ``__name__``.\n            rank_zero_only: Whether to force all logs to only occur on the rank zero process. Default is `False`.\n            extra: (Optional) A dict-like object which provides contextual information. See `logging.LoggerAdapter`.\n        \"\"\"\n        logger = logging.getLogger(name)\n        super().__init__(logger=logger, extra=extra)\n        self.rank_zero_only = rank_zero_only\n\n    def log(self, level: int, msg: str, rank: int | None = None, *args, **kwargs) -&gt; None:  # type: ignore\n        \"\"\"Delegate a log call to the underlying logger.\n\n        After prefixing its message with the rank\n        of the process it's being logged from. If `'rank'` is provided, then the log will only\n        occur on that rank/process.\n\n        Args:\n            level: The level to log at. Look at `logging.__init__.py` for more information.\n            msg: The message to log.\n            rank: The rank to log at.\n            args: Additional args to pass to the underlying logging function.\n            kwargs: Any additional keyword args to pass to the underlying logging function.\n        \"\"\"\n        if self.isEnabledFor(level):\n            msg, kwargs = self.process(msg, kwargs)  # type: ignore\n            current_rank = getattr(rank_zero_only, \"rank\", None)\n            if current_rank is None:\n                raise RuntimeError(\"The `rank_zero_only.rank` needs to be set before use\")  # noqa\n            msg = rank_prefixed_message(msg, current_rank)\n            if self.rank_zero_only:\n                if current_rank == 0:\n                    self.logger.log(level, msg, *args, **kwargs)\n            else:\n                if rank is None or current_rank == rank:\n                    self.logger.log(level, msg, *args, **kwargs)\n</code></pre>"},{"location":"api/utils/pylogger/#src.utils.pylogger.RankedLogger.__init__","title":"<code>__init__(name=__name__, rank_zero_only=False, extra=None)</code>","text":"<p>Initializes a multi-GPU-friendly python command line logger that logs.</p> <p>On all processes with their rank prefixed in the log message.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the logger. Default is <code>__name__</code>.</p> <code>__name__</code> <code>rank_zero_only</code> <code>bool</code> <p>Whether to force all logs to only occur on the rank zero process. Default is <code>False</code>.</p> <code>False</code> <code>extra</code> <code>Mapping[str, object] | None</code> <p>(Optional) A dict-like object which provides contextual information. See <code>logging.LoggerAdapter</code>.</p> <code>None</code> Source code in <code>src/utils/pylogger.py</code> <pre><code>def __init__(\n    self,\n    name: str = __name__,\n    rank_zero_only: bool = False,\n    extra: Mapping[str, object] | None = None,\n) -&gt; None:\n    \"\"\"Initializes a multi-GPU-friendly python command line logger that logs.\n\n    On all processes with their rank prefixed in the log message.\n\n    Args:\n        name: The name of the logger. Default is ``__name__``.\n        rank_zero_only: Whether to force all logs to only occur on the rank zero process. Default is `False`.\n        extra: (Optional) A dict-like object which provides contextual information. See `logging.LoggerAdapter`.\n    \"\"\"\n    logger = logging.getLogger(name)\n    super().__init__(logger=logger, extra=extra)\n    self.rank_zero_only = rank_zero_only\n</code></pre>"},{"location":"api/utils/pylogger/#src.utils.pylogger.RankedLogger.log","title":"<code>log(level, msg, rank=None, *args, **kwargs)</code>","text":"<p>Delegate a log call to the underlying logger.</p> <p>After prefixing its message with the rank of the process it's being logged from. If <code>'rank'</code> is provided, then the log will only occur on that rank/process.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>The level to log at. Look at <code>logging.__init__.py</code> for more information.</p> required <code>msg</code> <code>str</code> <p>The message to log.</p> required <code>rank</code> <code>int | None</code> <p>The rank to log at.</p> <code>None</code> <code>args</code> <p>Additional args to pass to the underlying logging function.</p> <code>()</code> <code>kwargs</code> <p>Any additional keyword args to pass to the underlying logging function.</p> <code>{}</code> Source code in <code>src/utils/pylogger.py</code> <pre><code>def log(self, level: int, msg: str, rank: int | None = None, *args, **kwargs) -&gt; None:  # type: ignore\n    \"\"\"Delegate a log call to the underlying logger.\n\n    After prefixing its message with the rank\n    of the process it's being logged from. If `'rank'` is provided, then the log will only\n    occur on that rank/process.\n\n    Args:\n        level: The level to log at. Look at `logging.__init__.py` for more information.\n        msg: The message to log.\n        rank: The rank to log at.\n        args: Additional args to pass to the underlying logging function.\n        kwargs: Any additional keyword args to pass to the underlying logging function.\n    \"\"\"\n    if self.isEnabledFor(level):\n        msg, kwargs = self.process(msg, kwargs)  # type: ignore\n        current_rank = getattr(rank_zero_only, \"rank\", None)\n        if current_rank is None:\n            raise RuntimeError(\"The `rank_zero_only.rank` needs to be set before use\")  # noqa\n        msg = rank_prefixed_message(msg, current_rank)\n        if self.rank_zero_only:\n            if current_rank == 0:\n                self.logger.log(level, msg, *args, **kwargs)\n        else:\n            if rank is None or current_rank == rank:\n                self.logger.log(level, msg, *args, **kwargs)\n</code></pre>"},{"location":"api/utils/rich_utils/","title":"Rich utils","text":"<p>Rich utils to print config tree.</p>"},{"location":"api/utils/rich_utils/#src.utils.rich_utils.enforce_tags","title":"<code>enforce_tags(cfg, save_to_file=False)</code>","text":"<p>Prompts user to input tags from command line if no tags are provided in config.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>A DictConfig composed by Hydra.</p> required <code>save_to_file</code> <code>bool</code> <p>Whether to export tags to the hydra output folder. Default is <code>False</code>.</p> <code>False</code> Source code in <code>src/utils/rich_utils.py</code> <pre><code>@rank_zero_only\ndef enforce_tags(cfg: DictConfig, save_to_file: bool = False) -&gt; None:\n    \"\"\"Prompts user to input tags from command line if no tags are provided in config.\n\n    Args:\n        cfg: A DictConfig composed by Hydra.\n        save_to_file: Whether to export tags to the hydra output folder. Default is ``False``.\n    \"\"\"\n    if not cfg.get(\"tags\"):\n        if \"id\" in HydraConfig().cfg.hydra.job:  # type: ignore\n            raise ValueError(\"Specify tags before launching a multirun!\")  # noqa\n\n        log.warning(\"No tags provided in config. Prompting user to input tags...\")\n        tags = Prompt.ask(\"Enter a list of comma separated tags\", default=\"dev\")\n        tags = [t.strip() for t in tags.split(\",\") if t != \"\"]\n\n        with open_dict(cfg):\n            cfg.tags = tags\n\n        log.info(f\"Tags: {cfg.tags}\")\n\n    if save_to_file:\n        with open(Path(cfg.paths.output_dir, \"tags.log\"), \"w\") as file:\n            rich.print(cfg.tags, file=file)\n</code></pre>"},{"location":"api/utils/rich_utils/#src.utils.rich_utils.print_config_tree","title":"<code>print_config_tree(cfg, print_order=('data', 'model', 'callbacks', 'logger', 'trainer', 'paths', 'extras'), resolve=False, save_to_file=False)</code>","text":"<p>Prints the contents of a DictConfig as a tree structure using the Rich library.</p> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>A DictConfig composed by Hydra.</p> required <code>print_order</code> <code>Sequence[str]</code> <p>Determines in what order config components are printed. Default is ``(\"data\", \"model\",</p> <code>('data', 'model', 'callbacks', 'logger', 'trainer', 'paths', 'extras')</code> <code>resolve</code> <code>bool</code> <p>Whether to resolve reference fields of DictConfig. Default is <code>False</code>.</p> <code>False</code> <code>save_to_file</code> <code>bool</code> <p>Whether to export config to the hydra output folder. Default is <code>False</code>.</p> <code>False</code> Source code in <code>src/utils/rich_utils.py</code> <pre><code>@rank_zero_only\ndef print_config_tree(\n    cfg: DictConfig,\n    print_order: Sequence[str] = (\n        \"data\",\n        \"model\",\n        \"callbacks\",\n        \"logger\",\n        \"trainer\",\n        \"paths\",\n        \"extras\",\n    ),\n    resolve: bool = False,\n    save_to_file: bool = False,\n) -&gt; None:\n    \"\"\"Prints the contents of a DictConfig as a tree structure using the Rich library.\n\n    Args:\n        cfg: A DictConfig composed by Hydra.\n        print_order: Determines in what order config components are printed. Default is ``(\"data\", \"model\",\n        \"callbacks\", \"logger\", \"trainer\", \"paths\", \"extras\")``.\n        resolve: Whether to resolve reference fields of DictConfig. Default is ``False``.\n        save_to_file: Whether to export config to the hydra output folder. Default is ``False``.\n    \"\"\"\n    style = \"dim\"\n    tree = rich.tree.Tree(\"CONFIG\", style=style, guide_style=style)\n\n    queue = []\n\n    # add fields from `print_order` to queue\n    for field in print_order:\n        queue.append(field) if field in cfg else log.warning(\n            f\"Field '{field}' not found in config. Skipping '{field}' config printing...\"\n        )\n\n    # add all the other fields to queue (not specified in `print_order`)\n    for field in cfg:\n        if field not in queue:\n            queue.append(str(field))\n\n    # generate config tree from queue\n    for field in queue:\n        branch = tree.add(field, style=style, guide_style=style)\n\n        config_group = cfg[field]\n        if isinstance(config_group, DictConfig):\n            branch_content = OmegaConf.to_yaml(config_group, resolve=resolve)\n        else:\n            branch_content = str(config_group)\n\n        branch.add(rich.syntax.Syntax(branch_content, \"yaml\"))\n\n    # print config tree\n    rich.print(tree)\n\n    # save config tree to file\n    if save_to_file:\n        with open(Path(cfg.paths.output_dir, \"config_tree.log\"), \"w\") as file:\n            rich.print(tree, file=file)\n</code></pre>"},{"location":"api/utils/utils/","title":"Utils","text":"<p>Utility functions for various tasks.</p>"},{"location":"api/utils/utils/#src.utils.utils.extras","title":"<code>extras(cfg)</code>","text":"<p>Applies optional utilities before the task is started.</p> Utilities <ul> <li>Ignoring python warnings</li> <li>Setting tags from command line</li> <li>Rich config printing</li> </ul> <p>Parameters:</p> Name Type Description Default <code>cfg</code> <code>DictConfig</code> <p>A DictConfig object containing the config tree.</p> required Source code in <code>src/utils/utils.py</code> <pre><code>def extras(cfg: DictConfig) -&gt; None:\n    \"\"\"Applies optional utilities before the task is started.\n\n    Utilities:\n        - Ignoring python warnings\n        - Setting tags from command line\n        - Rich config printing\n\n    Args:\n        cfg: A DictConfig object containing the config tree.\n    \"\"\"\n    # return if no `extras` config\n    if not cfg.get(\"extras\"):\n        log.warning(\"Extras config not found! &lt;cfg.extras=null&gt;\")\n        return\n\n    # disable python warnings\n    if cfg.extras.get(\"ignore_warnings\"):\n        log.info(\"Disabling python warnings! &lt;cfg.extras.ignore_warnings=True&gt;\")\n        warnings.filterwarnings(\"ignore\")\n\n    # prompt user to input tags from command line if none are provided in the config\n    if cfg.extras.get(\"enforce_tags\"):\n        log.info(\"Enforcing tags! &lt;cfg.extras.enforce_tags=True&gt;\")\n        rich_utils.enforce_tags(cfg, save_to_file=True)\n\n    # pretty print config tree using Rich library\n    if cfg.extras.get(\"print_config\"):\n        log.info(\"Printing config tree with Rich! &lt;cfg.extras.print_config=True&gt;\")\n        rich_utils.print_config_tree(cfg, resolve=True, save_to_file=True)\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.fetch_data","title":"<code>fetch_data(url)</code>","text":"<p>Fetches data from a URL.</p> Source code in <code>src/utils/utils.py</code> <pre><code>def fetch_data(url: str) -&gt; dict[str, Any] | None:\n    \"\"\"Fetches data from a URL.\"\"\"\n    response = requests.get(url)\n    if response.status_code == 200:\n        return cast(dict, response.json())\n    return None\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.file_lock","title":"<code>file_lock(filename, mode='r')</code>","text":"<p>This context manager is used to acquire a file lock on a file.</p> <p>particularly useful for shared resources in multi-process environments (multi GPU/TPU training).</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path</code> <p>Path to the file to lock</p> required <code>mode</code> <code>str</code> <p>The mode to open the file with, either \"r\" or \"w\"</p> <code>'r'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the mode is invalid (neither \"r\" nor \"w\")</p> Source code in <code>src/utils/utils.py</code> <pre><code>@contextlib.contextmanager\ndef file_lock(filename: Path, mode: str = \"r\") -&gt; Any:\n    \"\"\"This context manager is used to acquire a file lock on a file.\n\n    particularly useful for shared resources in multi-process environments (multi GPU/TPU training).\n\n    Args:\n        filename: Path to the file to lock\n        mode: The mode to open the file with, either \"r\" or \"w\"\n\n    Raises:\n        ValueError: If the mode is invalid (neither \"r\" nor \"w\")\n    \"\"\"\n    with open(filename, mode) as f:\n        try:\n            match mode:\n                case \"r\":\n                    fcntl.flock(f.fileno(), fcntl.LOCK_SH)\n                case \"w\":\n                    fcntl.flock(f.fileno(), fcntl.LOCK_EX)\n                case _:\n                    raise ValueError(\"Expected mode 'r' or 'w'.\")  # noqa\n            yield f\n        finally:\n            fcntl.flock(f.fileno(), fcntl.LOCK_UN)\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.file_lock_operation","title":"<code>file_lock_operation(file_name, operation)</code>","text":"<p>This function is used to perform an operation on a file while acquiring a lock on it.</p> <p>The lock is acquired using the <code>file_lock</code> context manager, and based on a file stored in a temporary folder</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>Path to the file to lock</p> required <code>operation</code> <code>Callable</code> <p>The operation to perform on the file</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of the operation</p> Source code in <code>src/utils/utils.py</code> <pre><code>@contextlib.contextmanager\ndef file_lock_operation(file_name: str, operation: Callable) -&gt; Any:\n    \"\"\"This function is used to perform an operation on a file while acquiring a lock on it.\n\n    The lock is acquired using the `file_lock` context manager, and based on a file stored in a temporary folder\n\n    Args:\n        file_name: Path to the file to lock\n        operation: The operation to perform on the file\n\n    Returns:\n        The result of the operation\n    \"\"\"\n    with tempfile.TemporaryDirectory() as temp_dir:\n        file_path = Path(temp_dir) / file_name\n        with file_lock(file_path, mode=\"w\"):\n            result = operation(file_path)\n        return result\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.get_metric_value","title":"<code>get_metric_value(metric_dict, metric_name)</code>","text":"<p>Safely retrieves value of the metric logged in LightningModule.</p> <p>Parameters:</p> Name Type Description Default <code>metric_dict</code> <code>dict[str, Any]</code> <p>A dict containing metric values.</p> required <code>metric_name</code> <code>str | None</code> <p>If provided, the name of the metric to retrieve.</p> required <p>Returns:</p> Type Description <code>None | float</code> <p>If a metric name was provided, the value of the metric.</p> Source code in <code>src/utils/utils.py</code> <pre><code>def get_metric_value(metric_dict: dict[str, Any], metric_name: str | None) -&gt; None | float:\n    \"\"\"Safely retrieves value of the metric logged in LightningModule.\n\n    Args:\n        metric_dict: A dict containing metric values.\n        metric_name: If provided, the name of the metric to retrieve.\n\n    Returns:\n        If a metric name was provided, the value of the metric.\n    \"\"\"\n    if not metric_name:\n        log.info(\"Metric name is None! Skipping metric value retrieval...\")\n        return None\n\n    if metric_name not in metric_dict:\n        raise ValueError(f\"Metric value not found! &lt;metric_name={metric_name}&gt;\\n\")  # noqa: TRY003\n\n    metric_value = metric_dict[metric_name].item()\n    log.info(f\"Retrieved metric value! &lt;{metric_name}={metric_value}&gt;\")\n\n    return float(metric_value)\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.process_data","title":"<code>process_data(url)</code>","text":"<p>Fetches data from a URL and processes it.</p> Source code in <code>src/utils/utils.py</code> <pre><code>def process_data(url: str) -&gt; int:\n    \"\"\"Fetches data from a URL and processes it.\"\"\"\n    data = fetch_data(url)\n    if data:\n        return len(data)  # Just an example of processing, counting data length\n    return 0\n</code></pre>"},{"location":"api/utils/utils/#src.utils.utils.task_wrapper","title":"<code>task_wrapper(task_func)</code>","text":"<p>Optional decorator that controls the failure behavior when executing the task function.</p> This wrapper can be used to <ul> <li>make sure loggers are closed even if the task function raises an exception (prevents multirun failure)</li> <li>save the exception to a <code>.log</code> file</li> <li>mark the run as failed with a dedicated file in the <code>logs/</code> folder (so we can find and rerun it later)</li> <li>etc. (adjust depending on your needs)</li> </ul> <p>Example: <pre><code>@utils.task_wrapper\ndef train(cfg: DictConfig) -&gt; Tuple[Dict[str, Any], Dict[str, Any]]:\n    ...\n    return metric_dict, object_dict\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>task_func</code> <code>Callable</code> <p>The task function to be wrapped.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The wrapped task function.</p> Source code in <code>src/utils/utils.py</code> <pre><code>def task_wrapper(task_func: Callable) -&gt; Callable:\n    \"\"\"Optional decorator that controls the failure behavior when executing the task function.\n\n    This wrapper can be used to:\n        - make sure loggers are closed even if the task function raises an exception (prevents multirun failure)\n        - save the exception to a `.log` file\n        - mark the run as failed with a dedicated file in the `logs/` folder (so we can find and rerun it later)\n        - etc. (adjust depending on your needs)\n\n    Example:\n    ```\n    @utils.task_wrapper\n    def train(cfg: DictConfig) -&gt; Tuple[Dict[str, Any], Dict[str, Any]]:\n        ...\n        return metric_dict, object_dict\n    ```\n\n    Args:\n        task_func: The task function to be wrapped.\n\n    Returns:\n        The wrapped task function.\n    \"\"\"\n\n    def wrap(cfg: DictConfig) -&gt; tuple[dict[str, Any], dict[str, Any]]:\n        # execute the task\n        try:\n            metric_dict, object_dict = task_func(cfg=cfg)\n\n        # things to do if exception occurs\n        except Exception as e:\n            # save exception to `.log` file\n            log.exception(\"\")\n\n            # some hyperparameter combinations might be invalid or cause out-of-memory errors\n            # so when using hparam search plugins like Optuna, you might want to disable\n            # raising the below exception to avoid multirun failure\n            raise e  # noqa: TRY201\n\n        # things to always do after either success or exception\n        finally:\n            # display output dir path in terminal\n            log.info(f\"Output dir: {cfg.paths.output_dir}\")\n\n            # always close wandb run (even if exception occurs so multirun won't fail)\n            if find_spec(\"wandb\"):  # check if wandb is installed\n                import wandb\n\n                if wandb.run:\n                    log.info(\"Closing wandb!\")\n                    wandb.finish()\n\n        return metric_dict, object_dict\n\n    return wrap\n</code></pre>"}]}